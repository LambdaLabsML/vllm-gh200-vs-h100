# vllm-gh200-vs-h100

This repo contains code used for benchmarking inference on both the gh200 and h100 with the Llama 3.1 70B model.
